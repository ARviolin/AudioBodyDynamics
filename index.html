<html>
<head>
    <meta charset="utf-8">
    <!--meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1"-->
    <title>Audio to Body Dynamics</title>

    <!-- CSS includes -->
    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
    <link href="mainpage.css" rel="stylesheet">
</head>
<body>

<div id="header" class="container-fluid">
    <div class="row">
        <h1>Audio to Body Dynamics</h1>
        <div class="authors">
            <a href="https://research.fb.com/people/shlizerman-eli/" target="new">Eli Shlizerman<sup>1,3</sup></a>
            &nbsp;
            <a href="https://www.linkedin.com/in/lucio-dery" target="new">Lucio M. Dery<sup>1,2</sup></a>
            &nbsp;
            <a href="https://www.linkedin.com/in/hayden-schoen-79673657" target="new">Hayden Schoen<sup>1</sup></a>
            &nbsp;
            <a href="https://research.fb.com/people/kemelmacher-shlizerman-ira/" target="new">Ira Kemelmacher-Shlizerman<sup>1,3</sup></a>
            <br>
            <sup>1</sup>Facebook Inc. &nbsp;&nbsp;&nbsp; <sup>2</sup>Stanford University &nbsp;&nbsp;&nbsp;<sup>3</sup>University of Washington<br><br>
        </div>

    </div>

    <div class="row" id="game-images" style="text-align:center;padding:0;margin:0">
          <div class="containere" id="image-containexr">
            <!--
              <video width="864" height="486" controls>
                  <source src="ARmusic_video.mp4" type="video/mp4">
              </video>
            -->
            <iframe width="864" height="486" src="https://www.youtube.com/embed/-GcdRBNP3GQ?rel=0&amp;showinfo=0"
                    frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen>
            </iframe>
              <br>
          </div>
    </div>
</div>

<div class="container">
    <h2>Abstract</h2>
We present a method that gets as input an audio of violin or piano playing, and outputs a video of skeleton predictions which are further used to animate an avatar. The key idea is to create an animation  of an avatar that moves their hands similarly to how a pianist or violinist would do,  just from audio.   Aiming for a fully detailed correct arms and fingers motion is the ultimate goal, however, it's not  clear if body movement can be predicted from music at all.  In this paper, we present the first result that shows that natural body dynamics can be predicted.  We built  an LSTM network that is trained  on violin and piano recital videos uploaded to the Internet. The predicted points are applied onto a rigged avatar to create the animation.
</div>

<div class="container" >
    <h2>Paper</h2>
    <div>
    <a href="ARmusic_paper_final.pdf" target="new">Paper pdf</a><br><br>
         <pre class="citation">@article{shliz2017aud,
    journal   = {arXiv preprint arXiv:},
    year      = {2017},
    author    = {Shlizerman, Eli and Dery, Lucio and Schoen, Hayden and Kemelmacher-Shlizerman, Ira},
    title     = {Audio to Body Dynamics}}
         </pre>
     </div>
</div>
<div class="container" >
  <h2>Contact</h2>
  <div>
  Eli Shlizerman <a href="mailto:shlizee@fb.com">shlizee@fb.com</a> , Ira Kemelmacher-Shlizerman <a href="mailto:kemelmi@fb.com">kemelmi@fb.com</a>
  </div>
</div>

<div id="footer">
</div>

<!-- Javascript includes -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>


</body></html>
